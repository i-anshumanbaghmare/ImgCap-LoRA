{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDhKs27pH2fLk2IlWIjrrO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Character Configuration"
      ],
      "metadata": {
        "id": "RnnkkF_S_scj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "\n",
        "DATA_IMG_DIR = \"data/images\"\n",
        "DATA_CAP_DIR = \"data/captions\"\n",
        "TEMP_DIR = \"temp\"\n",
        "\n",
        "VALID_EXTS = (\".jpg\", \".jpeg\", \".png\", \".webp\")\n",
        "\n",
        "RESIZE_PRESETS = {\n",
        "    \"Face (512x512)\": (512, 512),\n",
        "    \"Half Body (512x768)\": (512, 768),\n",
        "    \"Full Body (768x1024)\": (768, 1024)\n",
        "}\n",
        "\n",
        "os.makedirs(DATA_IMG_DIR, exist_ok=True)\n",
        "os.makedirs(DATA_CAP_DIR, exist_ok=True)\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Global State (Simple & Safe)\n",
        "# -----------------------------\n",
        "\n",
        "image_list = []\n",
        "current_index = 0\n",
        "character_name = \"person\"\n"
      ],
      "metadata": {
        "id": "hAXeE2p0_rLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Directory"
      ],
      "metadata": {
        "id": "BNM7dDdx_8Ud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Zip file Extractor"
      ],
      "metadata": {
        "id": "jOQNBlyAA1Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_zip(zip_path):\n",
        "    global image_list, current_index             # From out of the function\n",
        "\n",
        "    if os.path.exists(TEMP_DIR):\n",
        "        shutil.rmtree(TEMP_DIR)                  # Delete if already exist\n",
        "    os.makedirs(TEMP_DIR, exist_ok=True)         # Create Temporary Folder\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        z.extractall(TEMP_DIR)                   # Extract Zip file into Temporary Folder\n",
        "\n",
        "    image_list = []\n",
        "    for root, _, files in os.walk(TEMP_DIR):\n",
        "        for f in files:\n",
        "            if f.lower().endswith(VALID_EXTS):             # Extract only image\n",
        "                image_list.append(os.path.join(root, f))   #\n",
        "\n",
        "    image_list.sort()\n",
        "    current_index = 0\n",
        "\n",
        "    if len(image_list) == 0:\n",
        "        raise ValueError(\"No valid images found in ZIP\")\n",
        "\n",
        "    return load_current_image()\n"
      ],
      "metadata": {
        "id": "yJcJuD07A9_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Image Load"
      ],
      "metadata": {
        "id": "A6tGcQM1BSPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_current_image():\n",
        "    if not image_list:\n",
        "        return None\n",
        "    return Image.open(image_list[current_index]).convert(\"RGB\")\n",
        "\n",
        "def next_image():\n",
        "    global current_index\n",
        "    if current_index < len(image_list) - 1:\n",
        "        current_index += 1\n",
        "    return load_current_image()\n",
        "\n",
        "def prev_image():\n",
        "    global current_index\n",
        "    if current_index > 0:\n",
        "        current_index -= 1\n",
        "    return load_current_image()"
      ],
      "metadata": {
        "id": "i9502TRZBYyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving Logics"
      ],
      "metadata": {
        "id": "Dsg8KipjBitH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_processed(\n",
        "    img,\n",
        "    body_type,\n",
        "    caption_extra,\n",
        "    resize_preset,\n",
        "    resize_method\n",
        "):\n",
        "    idx = str(current_index + 1).zfill(4)\n",
        "    body_tag = body_type.lower().replace(\" \", \"\")\n",
        "    filename = f\"{idx}_{character_name}_{body_tag}.jpg\"\n",
        "\n",
        "    # Resize\n",
        "    if resize_preset != \"No Resize\":\n",
        "        size = RESIZE_PRESETS[resize_preset]\n",
        "        resample_map = {\n",
        "            \"Lanczos\": Image.LANCZOS,\n",
        "            \"Bicubic\": Image.BICUBIC,\n",
        "            \"Area\": Image.BOX\n",
        "        }\n",
        "        img = img.resize(size, resample=resample_map[resize_method])\n",
        "\n",
        "    img.save(os.path.join(DATA_IMG_DIR, filename), quality=95)\n",
        "\n",
        "    caption = f\"a photo of {character_name} person\"\n",
        "    if caption_extra.strip():\n",
        "        caption += \", \" + caption_extra.strip()\n",
        "\n",
        "    with open(os.path.join(DATA_CAP_DIR, filename.replace(\".jpg\", \".txt\")), \"w\") as f:\n",
        "        f.write(caption)\n",
        "\n",
        "    return f\"Saved {filename}\""
      ],
      "metadata": {
        "id": "t0CiPXTrBnWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Interface"
      ],
      "metadata": {
        "id": "Xr0V7cq-BxEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with gr.Blocks(title=\"Identity LoRA Dataset Builder\") as app:\n",
        "    gr.Markdown(\"## LoRA Dataset Builder\")\n",
        "\n",
        "    with gr.Row():\n",
        "        zip_input = gr.File(label=\"Upload ZIP (images only)\", file_types=[\".zip\"])\n",
        "        name_input = gr.Textbox(label=\"Character Name\")\n",
        "\n",
        "    load_btn = gr.Button(\"Load Dataset\")\n",
        "\n",
        "    with gr.Row():\n",
        "        image_display = gr.Image(label=\"Current Image\", interactive=True)\n",
        "        with gr.Column():\n",
        "            body_type = gr.Radio(\n",
        "                [\"Face\", \"Half\", \"Full\"],\n",
        "                label=\"Body Type\",\n",
        "                value=\"Face\"\n",
        "            )\n",
        "            caption_extra = gr.Textbox(\n",
        "                label=\"Optional Caption Add-on\",\n",
        "                placeholder=\"standing, natural light\"\n",
        "            )\n",
        "            resize_preset = gr.Dropdown(\n",
        "                [\"No Resize\"] + list(RESIZE_PRESETS.keys()),\n",
        "                label=\"Resize Preset\",\n",
        "                value=\"Face (512x512)\"\n",
        "            )\n",
        "            resize_method = gr.Radio(\n",
        "                [\"Lanczos\", \"Bicubic\", \"Area\"],\n",
        "                label=\"Resize Method\",\n",
        "                value=\"Lanczos\"\n",
        "            )\n",
        "\n",
        "    with gr.Row():\n",
        "        prev_btn = gr.Button(\"Previous\")\n",
        "        next_btn = gr.Button(\"Next\")\n",
        "        save_btn = gr.Button(\"Save Image + Caption\")\n",
        "\n",
        "    status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Bindings\n",
        "    # -----------------------------\n",
        "\n",
        "    def set_character_name(name):\n",
        "        global character_name\n",
        "        character_name = name.strip().lower()\n",
        "\n",
        "    name_input.change(set_character_name, name_input, None)\n",
        "\n",
        "    load_btn.click(extract_zip, zip_input, image_display)\n",
        "    next_btn.click(next_image, None, image_display)\n",
        "    prev_btn.click(prev_image, None, image_display)\n",
        "    save_btn.click(\n",
        "        save_processed,\n",
        "        [image_display, body_type, caption_extra, resize_preset, resize_method],\n",
        "        status\n",
        "    )\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "ZNSC4fwa3EAy",
        "outputId": "07a8c6fd-9d75-443a-b852-fc2b66389831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://805116c2aaa2c9a6cd.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://805116c2aaa2c9a6cd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging"
      ],
      "metadata": {
        "id": "qqk92_U-ylay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from PIL import Image, ImageOps\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "DATA_IMG_DIR = \"data/images\"\n",
        "DATA_CAP_DIR = \"data/captions\"\n",
        "TEMP_DIR = \"temp\"\n",
        "VALID_EXTS = (\".jpg\", \".jpeg\", \".png\", \".webp\")\n",
        "\n",
        "# Presets for LoRA training\n",
        "RESIZE_PRESETS = {\n",
        "    \"Face (512x512)\": (512, 512),\n",
        "    \"Half Body (512x768)\": (512, 768),\n",
        "    \"Full Body (768x1024)\": (768, 1024),\n",
        "    \"Square (1024x1024)\": (1024, 1024)\n",
        "}\n",
        "\n",
        "os.makedirs(DATA_IMG_DIR, exist_ok=True)\n",
        "os.makedirs(DATA_CAP_DIR, exist_ok=True)\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Global State\n",
        "# -----------------------------\n",
        "image_list = []\n",
        "current_index = 0\n",
        "character_name = \"person\"\n",
        "\n",
        "# -----------------------------\n",
        "# Utility Functions\n",
        "# -----------------------------\n",
        "def extract_zip(zip_file_obj):\n",
        "    global image_list, current_index\n",
        "    if zip_file_obj is None:\n",
        "        return None, \"Error: No ZIP file uploaded.\", \"N/A\"\n",
        "\n",
        "    print(f\"[DEBUG] Extracting ZIP: {zip_file_obj.name}\")\n",
        "\n",
        "    try:\n",
        "        # Clear and recreate temp directory\n",
        "        if os.path.exists(TEMP_DIR):\n",
        "            shutil.rmtree(TEMP_DIR)\n",
        "        os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "        with zipfile.ZipFile(zip_file_obj.name, 'r') as z:\n",
        "            z.extractall(TEMP_DIR)\n",
        "\n",
        "        # Collect images\n",
        "        image_list = []\n",
        "        for root, _, files in os.walk(TEMP_DIR):\n",
        "            for f in files:\n",
        "                if f.lower().endswith(VALID_EXTS):\n",
        "                    image_list.append(os.path.join(root, f))\n",
        "\n",
        "        image_list.sort()\n",
        "        current_index = 0\n",
        "\n",
        "        if len(image_list) == 0:\n",
        "            return None, \"Error: No valid images found in ZIP.\", \"N/A\"\n",
        "\n",
        "        img = load_current_image()\n",
        "        dims = f\"{img.width} x {img.height}\" if img else \"N/A\"\n",
        "        return img, f\"Loaded {len(image_list)} images.\", dims\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"Error during extraction: {str(e)}\", \"N/A\"\n",
        "\n",
        "def load_current_image():\n",
        "    if not image_list or current_index >= len(image_list):\n",
        "        return None\n",
        "    try:\n",
        "        img_path = image_list[current_index]\n",
        "        # Auto-orient handles rotation EXIF data which is common in photos\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img = ImageOps.exif_transpose(img)\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed to load image: {e}\")\n",
        "        return None\n",
        "\n",
        "def next_image():\n",
        "    global current_index\n",
        "    if image_list and current_index < len(image_list) - 1:\n",
        "        current_index += 1\n",
        "    return load_current_image()\n",
        "\n",
        "def prev_image():\n",
        "    global current_index\n",
        "    if image_list and current_index > 0:\n",
        "        current_index -= 1\n",
        "    return load_current_image()\n",
        "\n",
        "def set_character_name(name):\n",
        "    global character_name\n",
        "    character_name = name.strip().lower() or \"person\"\n",
        "\n",
        "# -----------------------------\n",
        "# Display Logic (Dynamic Pixel Sizes)\n",
        "# -----------------------------\n",
        "def get_dims(img_input):\n",
        "    \"\"\"\n",
        "    Parses the ImageEditor input to show dimensions.\n",
        "    Returns: (Original Dims String, Current Crop Dims String)\n",
        "    \"\"\"\n",
        "    if img_input is None:\n",
        "        return \"N/A\", \"N/A\"\n",
        "\n",
        "    # ImageEditor returns a dict: {'background': ..., 'layers': ..., 'composite': ...}\n",
        "    # 'composite' is the image with edits (crops) applied.\n",
        "    # 'background' is the original loaded image.\n",
        "\n",
        "    bg = img_input.get(\"background\")\n",
        "    comp = img_input.get(\"composite\")\n",
        "\n",
        "    orig_str = f\"{bg.width} x {bg.height}\" if bg else \"N/A\"\n",
        "\n",
        "    # If user hasn't cropped yet, composite might be same as background or None\n",
        "    # We prioritize showing the composite size if it exists\n",
        "    current = comp if comp is not None else bg\n",
        "    curr_str = f\"{current.width} x {current.height}\" if current else \"N/A\"\n",
        "\n",
        "    return orig_str, curr_str\n",
        "\n",
        "# -----------------------------\n",
        "# Save Logic\n",
        "# -----------------------------\n",
        "def save_processed(img_input, body_type, caption_extra, resize_preset, resize_method):\n",
        "    if img_input is None:\n",
        "        return \"Error: No image loaded.\"\n",
        "    if not image_list:\n",
        "        return \"Error: No dataset loaded.\"\n",
        "\n",
        "    # 1. Extract the actual image from ImageEditor dictionary\n",
        "    # 'composite' holds the cropped/edited version.\n",
        "    # If no edit made, it falls back to 'background'.\n",
        "    img = img_input.get(\"composite\")\n",
        "    if img is None:\n",
        "        img = img_input.get(\"background\")\n",
        "\n",
        "    if img is None:\n",
        "        return \"Error: Image data missing.\"\n",
        "\n",
        "    # Convert from RGBA (common in editor) to RGB\n",
        "    final_img = img.convert(\"RGB\")\n",
        "\n",
        "    debug_log = [f\"[DEBUG] Processing Image {current_index+1}\"]\n",
        "    debug_log.append(f\"[DEBUG] Post-Crop Size: {final_img.size}\")\n",
        "\n",
        "    try:\n",
        "        idx = str(current_index + 1).zfill(4)\n",
        "        body_tag = body_type.lower().replace(\" \", \"\")\n",
        "        filename = f\"{idx}_{character_name}_{body_tag}.jpg\"\n",
        "\n",
        "        # 2. Apply Resize Preset\n",
        "        if resize_preset != \"No Resize\":\n",
        "            if resize_preset in RESIZE_PRESETS:\n",
        "                target_size = RESIZE_PRESETS[resize_preset]\n",
        "\n",
        "                # Resample filter mapping\n",
        "                resample_map = {\n",
        "                    \"Lanczos\": Image.Resampling.LANCZOS,\n",
        "                    \"Bicubic\": Image.Resampling.BICUBIC,\n",
        "                }\n",
        "                f_method = resample_map.get(resize_method, Image.Resampling.LANCZOS)\n",
        "\n",
        "                final_img = final_img.resize(target_size, resample=f_method)\n",
        "                debug_log.append(f\"[DEBUG] Resized to {target_size} using {resize_method}\")\n",
        "            else:\n",
        "                debug_log.append(f\"[DEBUG] Unknown preset: {resize_preset}, skipping resize.\")\n",
        "\n",
        "        # 3. Save Image\n",
        "        save_path = os.path.join(DATA_IMG_DIR, filename)\n",
        "        final_img.save(save_path, quality=95)\n",
        "\n",
        "        # 4. Save Caption\n",
        "        caption = f\"a photo of {character_name} person\"\n",
        "        if caption_extra and caption_extra.strip():\n",
        "            caption += \", \" + caption_extra.strip()\n",
        "\n",
        "        cap_path = os.path.join(DATA_CAP_DIR, filename.replace(\".jpg\", \".txt\"))\n",
        "        with open(cap_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(caption)\n",
        "\n",
        "        return f\"Saved: {filename}\\nDims: {final_img.size}\\n\" + \"\\n\".join(debug_log)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error saving: {str(e)}\"\n",
        "\n",
        "# -----------------------------\n",
        "# Gradio Interface\n",
        "# -----------------------------\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"LoRA Dataset Builder\") as app:\n",
        "    gr.Markdown(\"## ‚úÇÔ∏è Identity LoRA Dataset Builder with Cropper\")\n",
        "\n",
        "    # --- Top Control Bar ---\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            zip_input = gr.File(label=\"1. Upload ZIP\", file_types=[\".zip\"])\n",
        "            load_btn = gr.Button(\"Load Images\", variant=\"primary\")\n",
        "        with gr.Column(scale=2):\n",
        "            name_input = gr.Textbox(label=\"Character Trigger Word\", value=\"anshu\")\n",
        "            status = gr.Textbox(label=\"System Status\", lines=2)\n",
        "\n",
        "    gr.HTML(\"<hr>\")\n",
        "\n",
        "    # --- Main Editor Area ---\n",
        "    with gr.Row():\n",
        "        # Left: Image Editor\n",
        "        with gr.Column(scale=3):\n",
        "            # interactive=True enables the cropping tool inside the image\n",
        "            image_editor = gr.ImageEditor(\n",
        "                label=\"Image Editor (Crop Here)\",\n",
        "                type=\"pil\",\n",
        "                crop_size=None, # Allows freeform cropping\n",
        "                interactive=True,\n",
        "                height=600\n",
        "            )\n",
        "\n",
        "            # Pixel Display Area\n",
        "            with gr.Row():\n",
        "                orig_dims = gr.Textbox(label=\"Original Size\", value=\"N/A\", interactive=False)\n",
        "                curr_dims = gr.Textbox(label=\"Current Crop Size\", value=\"N/A\", interactive=False)\n",
        "\n",
        "        # Right: Settings & Save\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 2. Settings\")\n",
        "            body_type = gr.Radio([\"Face\", \"Half Body\", \"Full Body\"], label=\"Type\", value=\"Face\")\n",
        "\n",
        "            # Using Presets as requested in original code, but applied AFTER crop\n",
        "            resize_preset = gr.Dropdown(\n",
        "                [\"No Resize\"] + list(RESIZE_PRESETS.keys()),\n",
        "                label=\"Target Output Size\",\n",
        "                value=\"Face (512x512)\"\n",
        "            )\n",
        "            resize_method = gr.Radio([\"Lanczos\", \"Bicubic\"], label=\"Filter\", value=\"Lanczos\")\n",
        "\n",
        "            caption_extra = gr.Textbox(label=\"Caption Tags\", placeholder=\"e.g. smiling, blue shirt\")\n",
        "\n",
        "            save_btn = gr.Button(\"üíæ Save Image + Caption\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            gr.Markdown(\"### Navigation\")\n",
        "            with gr.Row():\n",
        "                prev_btn = gr.Button(\"‚¨ÖÔ∏è Prev\")\n",
        "                next_btn = gr.Button(\"Next ‚û°Ô∏è\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # Event Wiring\n",
        "    # -----------------------------\n",
        "\n",
        "    # 1. Load ZIP\n",
        "    load_btn.click(\n",
        "        fn=extract_zip,\n",
        "        inputs=zip_input,\n",
        "        outputs=[image_editor, status, orig_dims]\n",
        "    )\n",
        "\n",
        "    # 2. Navigation\n",
        "    # We update editor AND the dimension text when moving images\n",
        "    prev_btn.click(prev_image, None, image_editor)\n",
        "    next_btn.click(next_image, None, image_editor)\n",
        "\n",
        "    # 3. Dynamic Dimension Updates\n",
        "    # Whenever the image content changes (loaded or edited/cropped), update the text boxes\n",
        "    image_editor.change(\n",
        "        fn=get_dims,\n",
        "        inputs=image_editor,\n",
        "        outputs=[orig_dims, curr_dims]\n",
        "    )\n",
        "\n",
        "    # 4. Save\n",
        "    save_btn.click(\n",
        "        fn=save_processed,\n",
        "        inputs=[image_editor, body_type, caption_extra, resize_preset, resize_method],\n",
        "        outputs=status\n",
        "    )\n",
        "\n",
        "    # 5. Name Update\n",
        "    name_input.change(set_character_name, name_input, None)\n",
        "\n",
        "# -----------------------------\n",
        "# Launch\n",
        "# -----------------------------\n",
        "app.launch(share=True) # share=True generates a public link"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "29_hwfV8qDPs",
        "outputId": "ba8fda51-6710-469f-bda3-9135b82327ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4237160282.py:198: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft(), title=\"LoRA Dataset Builder\") as app:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://831afed77d570acd31.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://831afed77d570acd31.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def get_original_size(input_data):\n",
        "    \"\"\"\n",
        "    Triggered when an image is uploaded.\n",
        "    Returns the pixel dimensions of the original image.\n",
        "    \"\"\"\n",
        "    if input_data is None:\n",
        "        return \"Waiting for upload...\", 100, 100\n",
        "\n",
        "    # ImageEditor returns a dictionary. We look at the 'background' (original)\n",
        "    # or 'composite' depending on state, but usually 'background' is the base.\n",
        "    # Note: If passing plain Image component, input_data is just the image.\n",
        "    # Here we use ImageEditor, so input_data is a dictionary.\n",
        "\n",
        "    image = input_data[\"background\"]\n",
        "    if image is None:\n",
        "        return \"Waiting for upload...\", 100, 100\n",
        "\n",
        "    w, h = image.size\n",
        "    return f\"Original Size: {w} x {h} pixels\", w, h\n",
        "\n",
        "def process_image(input_data, new_width, new_height):\n",
        "    \"\"\"\n",
        "    Triggered when the Resize button is clicked.\n",
        "    Takes the cropped image from the editor, resizes it, and returns the result.\n",
        "    \"\"\"\n",
        "    if input_data is None:\n",
        "        return None, \"No image to process\"\n",
        "\n",
        "    # In Gradio's ImageEditor, the 'composite' key holds the image\n",
        "    # as it looks in the editor (after user crops/draws).\n",
        "    image = input_data[\"composite\"]\n",
        "\n",
        "    if image is None:\n",
        "        # Fallback if no edits were made, use background\n",
        "        image = input_data[\"background\"]\n",
        "\n",
        "    if image is None:\n",
        "        return None, \"No image found.\"\n",
        "\n",
        "    # Perform Resizing\n",
        "    # converting to int because sliders might return floats\n",
        "    resized_img = image.resize((int(new_width), int(new_height)))\n",
        "\n",
        "    final_w, final_h = resized_img.size\n",
        "    return resized_img, f\"Final Size: {final_w} x {final_h} pixels\"\n",
        "\n",
        "# --- Building the Interface ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"## ‚úÇÔ∏è Interactive Image Cropper & Resizer\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # Left Column: Input and Controls\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 1. Upload & Crop\")\n",
        "            # ImageEditor allows the user to crop inside the UI\n",
        "            input_img = gr.ImageEditor(\n",
        "                type=\"pil\",\n",
        "                label=\"Editor\",\n",
        "                crop_size=None, # Allows freeform cropping\n",
        "                interactive=True\n",
        "            )\n",
        "\n",
        "            # Display Original Dimensions\n",
        "            original_info = gr.Textbox(label=\"Original Dimensions\", value=\"Waiting for upload...\")\n",
        "\n",
        "            gr.Markdown(\"### 2. Resize Settings\")\n",
        "            with gr.Row():\n",
        "                width_slider = gr.Number(label=\"Target Width\", value=500)\n",
        "                height_slider = gr.Number(label=\"Target Height\", value=500)\n",
        "\n",
        "            process_btn = gr.Button(\"Apply Crop & Resize\", variant=\"primary\")\n",
        "\n",
        "        # Right Column: Output\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 3. Result\")\n",
        "            output_img = gr.Image(type=\"pil\", label=\"Final Image\")\n",
        "            final_info = gr.Textbox(label=\"Final Dimensions\")\n",
        "\n",
        "    # --- Event Wiring ---\n",
        "\n",
        "    # When image is uploaded to editor, calculate original size\n",
        "    input_img.change(\n",
        "        fn=get_original_size,\n",
        "        inputs=input_img,\n",
        "        outputs=[original_info, width_slider, height_slider]\n",
        "    )\n",
        "\n",
        "    # When button is clicked, process the image\n",
        "    process_btn.click(\n",
        "        fn=process_image,\n",
        "        inputs=[input_img, width_slider, height_slider],\n",
        "        outputs=[output_img, final_info]\n",
        "    )\n",
        "\n",
        "# Launch the app directly in the notebook\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "ojkImCIF8KI-",
        "outputId": "299c62c4-6caa-47ff-b8a4-62b651e647ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-640698456.py:52: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4222b051ddcae26532.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4222b051ddcae26532.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}